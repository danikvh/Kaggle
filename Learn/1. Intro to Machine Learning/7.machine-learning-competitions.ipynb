{"cells":[{"cell_type":"markdown","metadata":{},"source":["**This notebook is an exercise in the [Introduction to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/machine-learning-competitions).**\n","\n","---\n"]},{"cell_type":"markdown","metadata":{},"source":["# Introduction\n","\n","In this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to apply what you've learned and move up the leaderboard.\n","\n","Begin by running the code cell below to set up code checking and the filepaths for the dataset."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-28T18:41:52.318374Z","iopub.status.busy":"2023-04-28T18:41:52.317838Z","iopub.status.idle":"2023-04-28T18:41:52.327066Z","shell.execute_reply":"2023-04-28T18:41:52.325597Z","shell.execute_reply.started":"2023-04-28T18:41:52.318336Z"},"trusted":true},"outputs":[],"source":["# Set up code checking\n","from learntools.core import binder\n","binder.bind(globals())\n","from learntools.machine_learning.ex7 import *\n","\n","# Set up filepaths\n","import os\n","if not os.path.exists(\"../input/train.csv\"):\n","    os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n","    os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\") "]},{"cell_type":"markdown","metadata":{},"source":["Here's some of the code you've written so far. Start by running it again."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-28T19:06:33.435812Z","iopub.status.busy":"2023-04-28T19:06:33.434826Z","iopub.status.idle":"2023-04-28T19:06:34.180863Z","shell.execute_reply":"2023-04-28T19:06:34.179661Z","shell.execute_reply.started":"2023-04-28T19:06:33.435715Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Validation MAE for Random Forest Model: 16,918\n"]}],"source":["# Import helpful libraries\n","import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","\n","# Load the data, and separate the target\n","iowa_file_path = '../input/home-data-for-ml-course/train.csv'\n","home_data = pd.read_csv(iowa_file_path)\n","y = home_data.SalePrice\n","\n","# Create X (After completing the exercise, you can return to modify this line!)\n","# Potential features: 'MSSubClass', 'LotArea','OverallQual' ,'OverallCond','YearBuilt',\n","# 'YearRemodAdd','1stFlrSF','2ndFlrSF', 'LowQualFinSF','GrLivArea', 'FullBath','HalfBath', 'BedroomAbvGr'\n","# 'KitchenAbvGr', 'TotRmsAbvGrd','Fireplaces', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch','3SsnPorch', \n","# 'ScreenPorch','PoolArea', 'MiscVal','MoSold', 'YrSold'\n","features = ['LotArea', 'YearBuilt', '1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','YearRemodAdd', \n","            'MSSubClass','OverallQual','OverallCond','WoodDeckSF','Fireplaces','HalfBath','GrLivArea',\n","           'ScreenPorch','PoolArea']\n","\n","# Select columns corresponding to features, and preview the data\n","X = home_data[features]\n","X.head()\n","\n","# Split into validation and training data\n","train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n","\n","# Define a random forest model\n","rf_model = RandomForestRegressor(random_state=1)\n","rf_model.fit(train_X, train_y)\n","rf_val_predictions = rf_model.predict(val_X)\n","rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n","\n","print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))"]},{"cell_type":"markdown","metadata":{},"source":["Choosing random features to find the best combination"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random features  18  in iteration  0\n","Validation MAE for Random Forest Model: 20,437\n","['OpenPorchSF', 'TotRmsAbvGrd', 'LowQualFinSF', 'WoodDeckSF', 'LotArea', 'YearRemodAdd', 'Fireplaces', 'MoSold', '3SsnPorch', 'HalfBath', 'PoolArea', 'KitchenAbvGr', 'YrSold', '2ndFlrSF', '1stFlrSF', 'MSSubClass', 'FullBath', 'YearBuilt']\n","Validation MAE for Random Forest Model: 18,036\n","['Fireplaces', 'TotRmsAbvGrd', 'ScreenPorch', 'HalfBath', 'MiscVal', '3SsnPorch', 'KitchenAbvGr', 'YearBuilt', 'OverallQual', 'LotArea', '2ndFlrSF', 'FullBath', 'MoSold', 'YrSold', 'OverallCond', '1stFlrSF', 'OpenPorchSF', 'GrLivArea']\n","Validation MAE for Random Forest Model: 17,604\n","['OpenPorchSF', 'Fireplaces', 'ScreenPorch', '2ndFlrSF', 'HalfBath', 'BedroomAbvGr', 'YearRemodAdd', 'YearBuilt', 'PoolArea', 'MSSubClass', 'OverallQual', 'EnclosedPorch', 'LotArea', 'WoodDeckSF', 'OverallCond', 'LowQualFinSF', 'GrLivArea', '3SsnPorch']\n","Random features  18  in iteration  20\n","Random features  18  in iteration  40\n","Validation MAE for Random Forest Model: 17,365\n","['YearRemodAdd', 'YearBuilt', 'BedroomAbvGr', 'WoodDeckSF', '2ndFlrSF', 'LowQualFinSF', 'FullBath', 'OverallQual', 'YrSold', 'LotArea', 'OverallCond', 'KitchenAbvGr', 'PoolArea', '1stFlrSF', 'Fireplaces', 'GrLivArea', 'OpenPorchSF', 'HalfBath']\n","Random features  18  in iteration  60\n","Random features  18  in iteration  80\n","Random features  18  in iteration  100\n","Random features  18  in iteration  120\n","Random features  18  in iteration  140\n","Random features  18  in iteration  160\n","Random features  18  in iteration  180\n","Random features  19  in iteration  0\n","Random features  19  in iteration  20\n","Validation MAE for Random Forest Model: 17,095\n","['BedroomAbvGr', 'FullBath', 'KitchenAbvGr', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'MiscVal', '2ndFlrSF', 'YrSold', 'ScreenPorch', '3SsnPorch', 'LowQualFinSF', 'MSSubClass', '1stFlrSF', 'PoolArea', 'Fireplaces', 'LotArea', 'YearBuilt', 'GrLivArea']\n","Random features  19  in iteration  40\n","Random features  19  in iteration  60\n","Random features  19  in iteration  80\n","Random features  19  in iteration  100\n","Random features  19  in iteration  120\n","Random features  19  in iteration  140\n","Random features  19  in iteration  160\n","Random features  19  in iteration  180\n","Random features  20  in iteration  0\n","Random features  20  in iteration  20\n","Random features  20  in iteration  40\n","Random features  20  in iteration  60\n","Random features  20  in iteration  80\n","Random features  20  in iteration  100\n","Random features  20  in iteration  120\n","Random features  20  in iteration  140\n","Random features  20  in iteration  160\n","Random features  20  in iteration  180\n","Validation MAE for Random Forest Model: 17,021\n","['PoolArea', 'OverallQual', '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'WoodDeckSF', 'ScreenPorch', 'FullBath', 'Fireplaces', 'MiscVal', '1stFlrSF', 'YearRemodAdd', 'OverallCond', 'KitchenAbvGr', 'YearBuilt', 'YrSold', 'MSSubClass', 'HalfBath', 'GrLivArea', 'LotArea']\n","Random features  21  in iteration  0\n","Random features  21  in iteration  20\n","Random features  21  in iteration  40\n","Random features  21  in iteration  60\n","Random features  21  in iteration  80\n","Random features  21  in iteration  100\n","Random features  21  in iteration  120\n","Random features  21  in iteration  140\n","Random features  21  in iteration  160\n","Random features  21  in iteration  180\n","Best combination found:\n","['PoolArea', 'OverallQual', '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'WoodDeckSF', 'ScreenPorch', 'FullBath', 'Fireplaces', 'MiscVal', '1stFlrSF', 'YearRemodAdd', 'OverallCond', 'KitchenAbvGr', 'YearBuilt', 'YrSold', 'MSSubClass', 'HalfBath', 'GrLivArea', 'LotArea']\n","20\n"]}],"source":["# Import helpful libraries\n","import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","import random\n","\n","# Load the data, and separate the target\n","iowa_file_path = '../input/home-data-for-ml-course/train.csv'\n","home_data = pd.read_csv(iowa_file_path)\n","y = home_data.SalePrice\n","\n","# Create X \n","features = ['MSSubClass', 'LotArea','OverallQual' ,'OverallCond','YearBuilt',\n","            'YearRemodAdd','1stFlrSF','2ndFlrSF', 'LowQualFinSF','GrLivArea', 'FullBath','HalfBath', 'BedroomAbvGr',\n","            'KitchenAbvGr', 'TotRmsAbvGrd','Fireplaces', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch','3SsnPorch', \n","            'ScreenPorch','PoolArea', 'MiscVal','MoSold', 'YrSold']\n","\n","best_number_random_features = 0\n","best_features = []\n","best_val_mae = float('inf')\n","\n","# Number of random features to choose (hyperparameter?)\n","for n in [18, 19, 20, 21]:\n","    # Best features that minimize the error\n","    for i in range(0,200):\n","        if (i%20==0): print(\"Random features \", n, \" in iteration \", i)\n","        # Select columns corresponding to features, and preview the data\n","        random_features = random.sample(features, n)\n","        X = home_data[random_features]\n","        X.head()\n","\n","        # Split into validation and training data\n","        train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n","\n","        # Define a random forest model\n","        rf_model = RandomForestRegressor(random_state=1)\n","        rf_model.fit(train_X, train_y)\n","        rf_val_predictions = rf_model.predict(val_X)\n","        rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n","\n","        if rf_val_mae < best_val_mae:\n","            best_number_random_features = n\n","            best_features = random_features\n","            best_val_mae = rf_val_mae\n","            print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n","            print(best_features)\n","\n","print(\"Best combination found:\")\n","print(best_features)\n","print(best_number_random_features)"]},{"cell_type":"markdown","metadata":{},"source":["Changing order feaures of the best result:"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration  0\n","Validation MAE for Random Forest Model: 17,131\n","New order:  ['MSSubClass', 'ScreenPorch', 'FullBath', 'Fireplaces', 'HalfBath', 'YrSold', 'YearRemodAdd', 'OverallQual', 'OverallCond', '2ndFlrSF', 'KitchenAbvGr', 'YearBuilt', 'BedroomAbvGr', 'WoodDeckSF', 'LotArea', '3SsnPorch', 'PoolArea', '1stFlrSF', 'GrLivArea', 'MiscVal']\n","Validation MAE for Random Forest Model: 17,086\n","New order:  ['OverallCond', 'YearBuilt', 'BedroomAbvGr', 'WoodDeckSF', 'HalfBath', 'MiscVal', '3SsnPorch', 'YearRemodAdd', 'YrSold', 'FullBath', 'PoolArea', 'KitchenAbvGr', 'OverallQual', 'MSSubClass', 'ScreenPorch', 'LotArea', 'GrLivArea', '2ndFlrSF', 'Fireplaces', '1stFlrSF']\n","Validation MAE for Random Forest Model: 17,048\n","New order:  ['1stFlrSF', 'LotArea', 'MSSubClass', 'BedroomAbvGr', 'OverallQual', 'YrSold', 'PoolArea', 'YearRemodAdd', 'OverallCond', 'HalfBath', 'Fireplaces', '2ndFlrSF', 'KitchenAbvGr', 'YearBuilt', 'ScreenPorch', '3SsnPorch', 'FullBath', 'WoodDeckSF', 'MiscVal', 'GrLivArea']\n","Iteration  20\n","Validation MAE for Random Forest Model: 16,997\n","New order:  ['3SsnPorch', 'PoolArea', 'LotArea', 'YrSold', 'KitchenAbvGr', 'FullBath', 'YearRemodAdd', 'YearBuilt', 'OverallQual', 'HalfBath', '1stFlrSF', 'Fireplaces', 'MSSubClass', 'OverallCond', 'BedroomAbvGr', 'ScreenPorch', 'MiscVal', 'GrLivArea', 'WoodDeckSF', '2ndFlrSF']\n","Iteration  40\n","Validation MAE for Random Forest Model: 16,939\n","New order:  ['ScreenPorch', 'WoodDeckSF', '1stFlrSF', 'YrSold', 'GrLivArea', 'YearBuilt', 'OverallQual', 'LotArea', 'Fireplaces', 'MSSubClass', 'YearRemodAdd', 'KitchenAbvGr', '3SsnPorch', 'HalfBath', 'OverallCond', 'FullBath', 'BedroomAbvGr', '2ndFlrSF', 'MiscVal', 'PoolArea']\n","Iteration  60\n","Iteration  80\n","Iteration  100\n","Iteration  120\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[18], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Define a random forest model\u001b[39;00m\n\u001b[0;32m     18\u001b[0m rf_model \u001b[39m=\u001b[39m RandomForestRegressor(random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m rf_model\u001b[39m.\u001b[39;49mfit(train_X, train_y)\n\u001b[0;32m     20\u001b[0m rf_val_predictions \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mpredict(val_X)\n\u001b[0;32m     21\u001b[0m rf_val_mae \u001b[39m=\u001b[39m mean_absolute_error(rf_val_predictions, val_y)\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","File \u001b[1;32mc:\\Users\\Dani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["best_features = ['PoolArea', 'OverallQual', '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'WoodDeckSF', 'ScreenPorch', \n","                 'FullBath', 'Fireplaces', 'MiscVal', '1stFlrSF', 'YearRemodAdd', 'OverallCond', 'KitchenAbvGr', \n","                 'YearBuilt', 'YrSold', 'MSSubClass', 'HalfBath', 'GrLivArea', 'LotArea']\n","best_val_mae = float('inf')\n","\n","# Best features that minimize the error\n","for i in range(0,1000):\n","    if (i%20==0): print(\"Iteration \", i)\n","    # Select columns corresponding to features, and preview the data\n","    random_features = random.sample(best_features, 20)\n","    X = home_data[random_features]\n","    X.head()\n","\n","    # Split into validation and training data\n","    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n","\n","    # Define a random forest model\n","    rf_model = RandomForestRegressor(random_state=1)\n","    rf_model.fit(train_X, train_y)\n","    rf_val_predictions = rf_model.predict(val_X)\n","    rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n","\n","    if rf_val_mae < best_val_mae:\n","        best_features = random_features\n","        best_val_mae = rf_val_mae\n","        print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n","        print(\"New order: \", best_features)\n","\n","print(\"Best combination found:\")\n","print(best_features)"]},{"cell_type":"markdown","metadata":{},"source":["# Train a model for the competition\n","\n","The code cell above trains a Random Forest model on **`train_X`** and **`train_y`**.  \n","\n","Use the code cell below to build a Random Forest model and train it on all of **`X`** and **`y`**."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-28T18:42:22.805951Z","iopub.status.busy":"2023-04-28T18:42:22.804512Z","iopub.status.idle":"2023-04-28T18:42:23.359158Z","shell.execute_reply":"2023-04-28T18:42:23.357596Z","shell.execute_reply.started":"2023-04-28T18:42:22.805907Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div>"],"text/plain":["RandomForestRegressor(random_state=1)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# To improve accuracy, create a new Random Forest model which you will train on all training data\n","rf_model_on_full_data = RandomForestRegressor(random_state=1)\n","\n","# fit rf_model_on_full_data on all data from the training data\n","rf_model_on_full_data.fit(X,y)"]},{"cell_type":"markdown","metadata":{},"source":["Now, read the file of \"test\" data, and apply your model to make predictions."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-28T18:44:51.774673Z","iopub.status.busy":"2023-04-28T18:44:51.774186Z","iopub.status.idle":"2023-04-28T18:44:51.846031Z","shell.execute_reply":"2023-04-28T18:44:51.844654Z","shell.execute_reply.started":"2023-04-28T18:44:51.774635Z"},"trusted":true},"outputs":[],"source":["# path to file you will use for predictions\n","test_data_path = '../input/home-data-for-ml-course/train.csv'\n","\n","# read test data file using pandas\n","test_data = pd.read_csv(test_data_path)\n","\n","# create test_X which comes from test_data but includes only the columns you used for prediction.\n","# The list of columns is stored in a variable called features\n","test_X = test_data[features]\n","\n","# make predictions which we will submit. \n","test_preds = rf_model_on_full_data.predict(test_X)\n","\n","# Comprobar el error\n","#print(test_data.columns)\n","# rf_val_mae = mean_absolute_error(test_preds, test_Y)"]},{"cell_type":"markdown","metadata":{},"source":["Before submitting, run a check to make sure your `test_preds` have the right format."]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-04-28T18:44:54.695846Z","iopub.status.busy":"2023-04-28T18:44:54.694433Z","iopub.status.idle":"2023-04-28T18:44:54.706949Z","shell.execute_reply":"2023-04-28T18:44:54.705504Z","shell.execute_reply.started":"2023-04-28T18:44:54.695785Z"},"trusted":true},"outputs":[{"data":{"application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 1.0, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_CheckSubmittablePreds\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["<span style=\"color:#33cc33\">Correct</span>"],"text/plain":["Correct"]},"metadata":{},"output_type":"display_data"}],"source":["# Check your answer (To get credit for completing the exercise, you must get a \"Correct\" result!)\n","step_1.check()\n","# step_1.solution()"]},{"cell_type":"markdown","metadata":{},"source":["# Generate a submission\n","\n","Run the code cell below to generate a CSV file with your predictions that you can use to submit to the competition."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-04-28T18:45:00.847966Z","iopub.status.busy":"2023-04-28T18:45:00.847251Z","iopub.status.idle":"2023-04-28T18:45:00.858025Z","shell.execute_reply":"2023-04-28T18:45:00.856582Z","shell.execute_reply.started":"2023-04-28T18:45:00.847922Z"},"trusted":true},"outputs":[],"source":["# Run the code to save predictions in the format used for competition scoring\n","\n","output = pd.DataFrame({'Id': test_data.Id,\n","                       'SalePrice': test_preds})\n","output.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Submit to the competition\n","\n","To test your results, you'll need to join the competition (if you haven't already).  So open a new window by clicking on **[this link](https://www.kaggle.com/c/home-data-for-ml-course)**.  Then click on the **Join Competition** button.\n","\n","![join competition image](https://storage.googleapis.com/kaggle-media/learn/images/axBzctl.png)\n","\n","Next, follow the instructions below:\n","1. Begin by clicking on the **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n","2. Ensure that the **Save and Run All** option is selected, and then click on the **Save** button.\n","3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n","4. Click on the **Data** tab near the top of the screen.  Then, click on the file you would like to submit, and click on the **Submit** button to submit your results to the leaderboard.\n","\n","You have now successfully submitted to the competition!\n","\n","If you want to keep working to improve your performance, select the **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n","\n","\n","# Continue Your Progress\n","There are many ways to improve your model, and **experimenting is a great way to learn at this point.**\n","\n","The best way to improve your model is to add features.  To add more features to the data, revisit the first code cell, and change this line of code to include more column names:\n","```python\n","features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n","```\n","\n","Some features will cause errors because of issues like missing values or non-numeric data types.  Here is a complete list of potential columns that you might like to use, and that won't throw errors:\n","- 'MSSubClass'\n","- 'LotArea'\n","- 'OverallQual' \n","- 'OverallCond' \n","- 'YearBuilt'\n","- 'YearRemodAdd' \n","- '1stFlrSF'\n","- '2ndFlrSF' \n","- 'LowQualFinSF' \n","- 'GrLivArea'\n","- 'FullBath'\n","- 'HalfBath'\n","- 'BedroomAbvGr' \n","- 'KitchenAbvGr' \n","- 'TotRmsAbvGrd' \n","- 'Fireplaces' \n","- 'WoodDeckSF' \n","- 'OpenPorchSF'\n","- 'EnclosedPorch' \n","- '3SsnPorch' \n","- 'ScreenPorch' \n","- 'PoolArea' \n","- 'MiscVal' \n","- 'MoSold' \n","- 'YrSold'\n","\n","Look at the list of columns and think about what might affect home prices.  To learn more about each of these features, take a look at the data description on the **[competition page](https://www.kaggle.com/c/home-data-for-ml-course/data)**.\n","\n","After updating the code cell above that defines the features, re-run all of the code cells to evaluate the model and generate a new submission file.  \n","\n","\n","# What's next?\n","\n","As mentioned above, some of the features will throw an error if you try to use them to train your model.  The **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** course will teach you how to handle these types of features. You will also learn to use **xgboost**, a technique giving even better accuracy than Random Forest.\n","\n","The **[Pandas](https://kaggle.com/Learn/Pandas)** course will give you the data manipulation skills to quickly go from conceptual idea to implementation in your data science projects. \n","\n","You are also ready for the **[Deep Learning](https://kaggle.com/Learn/intro-to-Deep-Learning)** course, where you will build models with better-than-human level performance at computer vision tasks."]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","\n","\n","\n","*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-machine-learning/discussion) to chat with other learners.*"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
